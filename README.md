Here is a **GitHub-ready `README.md` with badges**, written to **look professional, serious, and research-grade** â€” not like a hobby repo.

You can paste this **as-is** into GitHub.

---

# ğŸ” Detecting Multi-Face Registration Attacks in Federated Face Recognition Systems

![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)
![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20Linux-lightgrey)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Research](https://img.shields.io/badge/type-Research%20Project-purple)
![Status](https://img.shields.io/badge/status-Completed-success)
![Privacy](https://img.shields.io/badge/privacy-preserving-important)

> **Unsupervised, identity-level detection of enrollment-time attacks in federated face recognition systems.**

---

## ğŸ“Œ Overview

This repository contains the complete implementation of a **security-focused research project** that studies and detects a critical enrollment-time vulnerability in federated face recognition systems known as the **Multi-Face Registration Attack**.

In this attack, a malicious federated client registers facial images from **multiple distinct individuals under a single identity label**, compromising identity integrity while remaining invisible to standard recognition accuracy metrics.

We propose a **privacy-preserving, unsupervised detection framework** based on **identity-level embedding geometry**, without using supervised labels or accessing raw biometric data.

---

## ğŸ¯ Key Contributions

* âœ” Formal definition of the **Multi-Face Registration Attack**
* âœ” Realistic **non-IID federated enrollment simulation**
* âœ” Custom **attack dataset generation pipeline**
* âœ” **Embedding-based identity integrity analysis**
* âœ” **Unsupervised anomaly detection** using max cosine distance
* âœ” Leakage-free, reproducible experimental pipeline

---

## ğŸ§  Core Insight

* Legitimate identities form **compact clusters** in embedding space
* Multi-face registrations introduce **outlier geometry**
* **Maximum cosine distance** reliably exposes identity compromise

This work shifts evaluation from **accuracy-centric metrics** to **identity integrity analysis**.

---

## ğŸ—ï¸ Repository Structure

```
Face recogination project/
â”‚
â”œâ”€â”€ Celeba/
â”‚   â”œâ”€â”€ identity_CelebA.txt
â”‚   â””â”€â”€ img_align_celeba/
â”‚
â”œâ”€â”€ data_processed/
â”‚   â”œâ”€â”€ celeba_identities/
â”‚   â”œâ”€â”€ splits/
â”‚   â”œâ”€â”€ federated/
â”‚   â”‚   â”œâ”€â”€ clients_10/
â”‚   â”‚   â”œâ”€â”€ clients_20/
â”‚   â”‚   â””â”€â”€ clients_50/
â”‚   â””â”€â”€ attack_dataset/
â”‚       â”œâ”€â”€ NormalPairs/
â”‚       â”œâ”€â”€ AttackPairs/
â”‚       â””â”€â”€ attack_metadata.json
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ roc_embedding_detection.pdf
â”‚   â””â”€â”€ score_distribution.pdf
â”‚
â”œâ”€â”€ separate_celeba_identities.py
â”œâ”€â”€ split_train_val_test.py
â”œâ”€â”€ create_federated_clients.py
â”œâ”€â”€ generate_multiface_attack.py
â”œâ”€â”€ embedding_detection.py
â”‚
â””â”€â”€ README.md
```

---

## ğŸ” Correct Execution Flow (IMPORTANT)

Run scripts **strictly in the following order**:

### 1ï¸âƒ£ Prepare identity-wise dataset *(run once)*

```bash
python separate_celeba_identities.py
```

### 2ï¸âƒ£ Create identity-disjoint splits *(run once, lock forever)*

```bash
python split_train_val_test.py
```

### 3ï¸âƒ£ Generate federated clients *(safe to rerun)*

```bash
python create_federated_clients.py
```

### 4ï¸âƒ£ Simulate multi-face registration attacks *(safe to rerun)*

```bash
python generate_multiface_attack.py
```

### 5ï¸âƒ£ Run detection and evaluation

```bash
python embedding_detection.py
```

âš ï¸ **Never regenerate identity splits mid-project** â€” this invalidates all experiments.

---

## ğŸ§ª Detection Method

* **Embedding Model:** ResNet-50 (pretrained, fixed extractor)
* **Normalization:** L2 normalization
* **Anomaly Score:** Maximum cosine distance to identity centroid
* **Detection Type:** Unsupervised
* **Privacy:** No raw images shared or centralized

---

## ğŸ“Š Experimental Results

### Dataset Statistics

* Total identities evaluated: **10,866**
* Normal identities: **10,824**
* Attack identities: **42**

### Detection Performance

| Metric         | Value     |
| -------------- | --------- |
| ROC-AUC        | **0.988** |
| TPR @ 1% FPR   | **71.4%** |
| TPR @ 0.1% FPR | **26.2%** |

Clear separation is observed between normal and compromised identities in embedding space.

---

## ğŸ” Threat Model

* Adversary controls one or more federated clients
* Attack occurs during **identity enrollment**
* No model poisoning or adversarial images
* Operates under realistic federated constraints

---

## ğŸš« Non-Goals

This project intentionally does **not** include:

* âŒ Supervised classifier training
* âŒ Grad-CAM / LIME explanations
* âŒ Centralized biometric storage
* âŒ Assumption of trusted enrollment

---

## ğŸš€ Future Work

* Multi-seed stability analysis (mean Â± std)
* Explainable AI for forensic evidence
* Live federated training integration
* Cross-dataset and cross-modal evaluation
* Adaptive adversarial strategies

---

## ğŸ“š References

* McMahan et al., *Communication-Efficient Learning of Deep Networks from Decentralized Data*, AISTATS 2017
* Deng et al., *ArcFace*, CVPR 2019
* Liu et al., *CelebA Dataset*, ICCV 2015

---

## ğŸ‘¤ Author

**Mahesh Kumar Tippanu**
M.Tech â€“ Computer Science and Engineering
GITAM University, Visakhapatnam
ğŸ“§ [maheshkumartippanu@gmail.com](mailto:maheshkumartippanu@gmail.com)

---

## ğŸ§¾ License

This project is licensed under the **MIT License** â€” see the `LICENSE` file for details.
